{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1OqpOipCCkK3gx-o4tVJlbuTYDbbqZ8tD","timestamp":1623310648904}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"HqMcg3Hb2N3Y"},"source":["### Yolo v5 다운로드 및 설치"]},{"cell_type":"code","metadata":{"id":"3CwoCtHOZnPo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686062699192,"user_tz":-540,"elapsed":12432,"user":{"displayName":"Jeolme","userId":"16749325847430807303"}},"outputId":"480e3678-8375-4509-d927-eb76e6a9c202"},"source":["!git clone https://github.com/ultralytics/yolov5\n","!cd yolov5;pip install -qr requirements.txt\n"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 15973, done.\u001b[K\n","remote: Counting objects: 100% (142/142), done.\u001b[K\n","remote: Compressing objects: 100% (67/67), done.\u001b[K\n","remote: Total 15973 (delta 87), reused 113 (delta 75), pack-reused 15831\u001b[K\n","Receiving objects: 100% (15973/15973), 14.60 MiB | 7.44 MiB/s, done.\n","Resolving deltas: 100% (10956/10956), done.\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m595.4/595.4 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","metadata":{"id":"kqWGfAn2mI9s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686062722104,"user_tz":-540,"elapsed":22914,"user":{"displayName":"Jeolme","userId":"16749325847430807303"}},"outputId":"f22306e6-c1a4-457e-bd6f-3b2bd4864dac"},"source":["# Google Drive 접근을 위한 Mount 적용. \n","import os, sys \n","from google.colab import drive \n","\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"OufKe0qemJAg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686062722104,"user_tz":-540,"elapsed":4,"user":{"displayName":"Jeolme","userId":"16749325847430807303"}},"outputId":"17bded78-775d-43c0-ed77-b5cbab3ecd16"},"source":["# soft link로 Google Drive Directory 연결. \n","!ln -s /content/gdrive/My\\ Drive/ /mydrive\n","!ls /mydrive\n","\n","# Google Drive 밑에 Directory 생성. 이미 생성 되어 있을 시 오류 발생. \n","!mkdir \"/mydrive/ultra_workdir\""],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["'Backup 2023-04-13.zip'   cropped_images   raw_images\t  ultra_workdir\n","'Colab Notebooks'\t  LP_data\t   sample_image  '제목 없는 문서.gdoc'\n","mkdir: cannot create directory ‘/mydrive/ultra_workdir’: File exists\n"]}]},{"cell_type":"markdown","metadata":{"id":"1cDgV03PBrjj"},"source":["### Dataset용 yaml 파일을 생성하고 학습 수행\n","* yolo v5는 모델이 yolov5s(small), yolov5m(middle), yolov5l(large), yolov5x(extra large)로 되어있음. weight 인자값으로 이들중 하나를 입력해 줌\n"]},{"cell_type":"code","metadata":{"id":"DNmkMzDSmJDT"},"source":["### batch size는 8로 정할것. 16으로 설정시 성능이 좋아지지 않음. epoch는 30번으로 설정.\n","### 번호판 검출의 경우 상대적으로 mAP:0.5~0.95 Detection 성능이 좋지 못함. \n","### 학습데이터가 적은것도 이유지만, Object 사이즈가 상대적으로 작아서 그런듯 함. \n","!cd /content/yolov5; python train.py --img 640 --batch 8 --epochs 150 --data /content/gdrive/MyDrive/LP_data/LP_data.yaml --weights yolov5l.pt \\\n","                                     --project=/mydrive/ultra_workdir --name LP --exist-ok "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mykCHLU22MdC"},"source":["### 단일 검출 모델(raw_images)에 대한 inference 수행"]},{"cell_type":"code","metadata":{"id":"ryBbBGko30zJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686062780347,"user_tz":-540,"elapsed":58245,"user":{"displayName":"Jeolme","userId":"16749325847430807303"}},"outputId":"9bc88789-0b98-4da1-dcc1-b3a6753d8e7f"},"source":["# raw_image 파일 inference \n","!cd /content/yolov5; python val.py --weights /mydrive/ultra_workdir/LP/weights/best.pt  \\\n","                           --data /content/gdrive/MyDrive/LP_data/LP_data.yaml \\\n","                           --project /content/data/output --name=raw_test_result --exist-ok --img 640 --iou 0.65"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mdata=/content/gdrive/MyDrive/LP_data/LP_data.yaml, weights=['/mydrive/ultra_workdir/LP/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.65, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=/content/data/output, name=raw_test_result, exist_ok=True, half=False, dnn=False\n","YOLOv5 🚀 v7.0-177-g89c3040 Python-3.10.11 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","\n","Fusing layers... \n","Model summary: 267 layers, 46108278 parameters, 0 gradients, 107.6 GFLOPs\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100% 755k/755k [00:00<00:00, 108MB/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/LP_data/val/labels... 0 images, 38 backgrounds, 0 corrupt:  64% 38/59 [00:26<00:14,  1.43it/s]\n","Traceback (most recent call last):\n","  File \"/content/yolov5/utils/dataloaders.py\", line 491, in __init__\n","    assert cache['hash'] == get_hash(self.label_files + self.im_files)  # identical hash\n","AssertionError\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 856, in next\n","    item = self._items.popleft()\n","IndexError: pop from an empty deque\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/content/yolov5/val.py\", line 409, in <module>\n","    main(opt)\n","  File \"/content/yolov5/val.py\", line 380, in main\n","    run(**vars(opt))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n","    return func(*args, **kwargs)\n","  File \"/content/yolov5/val.py\", line 175, in run\n","    dataloader = create_dataloader(data[task],\n","  File \"/content/yolov5/utils/dataloaders.py\", line 124, in create_dataloader\n","    dataset = LoadImagesAndLabels(\n","  File \"/content/yolov5/utils/dataloaders.py\", line 493, in __init__\n","    cache, exists = self.cache_labels(cache_path, prefix), False  # run cache ops\n","  File \"/content/yolov5/utils/dataloaders.py\", line 617, in cache_labels\n","    for im_file, lb, shape, segments, nm_f, nf_f, ne_f, nc_f, msg in pbar:\n","  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1178, in __iter__\n","    for obj in iterable:\n","  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 861, in next\n","    self._cond.wait(timeout)\n","  File \"/usr/lib/python3.10/threading.py\", line 320, in wait\n","    waiter.acquire()\n","KeyboardInterrupt\n","^C\n"]}]},{"cell_type":"markdown","source":["### 이중 검출 모델(car_images)에 대한 inference 수행 "],"metadata":{"id":"FL3SWO_G067d"}},{"cell_type":"code","source":["# car_image 파일 inference \n","!cd /content/yolov5; python val.py --weights /mydrive/ultra_workdir/LP/weights/best.pt  \\\n","                           --data /content/gdrive/MyDrive/LP_data/LP_data.yaml \\\n","                           --project /content/data/output --name=car_test_result --exist-ok --img 640 --iou 0.65"],"metadata":{"id":"q_HLUeKG06Rq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 단일 검출 모델(raw_images)에 대한 실사용"],"metadata":{"id":"55CTavxjOQek"}},{"cell_type":"code","source":["!cd /content/yolov5;python detect.py --source /content/gdrive/MyDrive/LP_data/val/images \\\n","                            --weights /mydrive/ultra_workdir/LP/weights/best.pt  --conf 0.3 \\\n","                            --project=/content/data/output --name=run_image --exist-ok --line-thickness 2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SoFzKRDJLWQi","executionInfo":{"status":"ok","timestamp":1686065940945,"user_tz":-540,"elapsed":53975,"user":{"displayName":"Jeolme","userId":"16749325847430807303"}},"outputId":"52238294-48ca-4188-99f4-a8366ad051ef"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/mydrive/ultra_workdir/LP/weights/best.pt'], source=/content/gdrive/MyDrive/LP_data/val/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.3, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=/content/data/output, name=run_image, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLOv5 🚀 v7.0-177-g89c3040 Python-3.10.11 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","\n","Fusing layers... \n","Model summary: 267 layers, 46108278 parameters, 0 gradients, 107.6 GFLOPs\n","image 1/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (100).JPEG: 384x640 3 Llicense_Plates, 45.3ms\n","image 2/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (104).JPEG: 384x640 4 Llicense_Plates, 32.1ms\n","image 3/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (108).JPEG: 384x640 3 Llicense_Plates, 32.1ms\n","image 4/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (112).JPEG: 384x640 2 Llicense_Plates, 32.1ms\n","image 5/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (116).JPEG: 384x640 4 Llicense_Plates, 32.1ms\n","image 6/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (12).JPEG: 384x640 4 Llicense_Plates, 32.1ms\n","image 7/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (16).JPEG: 384x640 3 Llicense_Plates, 32.1ms\n","image 8/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (2).JPEG: 384x640 3 Llicense_Plates, 32.1ms\n","image 9/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (20).JPEG: 384x640 3 Llicense_Plates, 32.1ms\n","image 10/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (24).JPEG: 384x640 2 Llicense_Plates, 32.1ms\n","image 11/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (28).JPEG: 384x640 4 Llicense_Plates, 32.1ms\n","image 12/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (32).JPEG: 384x640 4 Llicense_Plates, 32.1ms\n","image 13/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (36).JPEG: 384x640 4 Llicense_Plates, 32.1ms\n","image 14/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (40).JPEG: 384x640 2 Llicense_Plates, 32.1ms\n","image 15/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (44).JPEG: 384x640 2 Llicense_Plates, 32.1ms\n","image 16/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (48).JPEG: 384x640 2 Llicense_Plates, 32.1ms\n","image 17/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (52).JPEG: 384x640 3 Llicense_Plates, 32.1ms\n","image 18/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (56).JPEG: 384x640 3 Llicense_Plates, 32.1ms\n","image 19/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (6).JPEG: 384x640 5 Llicense_Plates, 32.1ms\n","image 20/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (60).JPEG: 384x640 3 Llicense_Plates, 32.1ms\n","image 21/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (64).JPEG: 384x640 5 Llicense_Plates, 32.1ms\n","image 22/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (68).JPEG: 384x640 4 Llicense_Plates, 32.1ms\n","image 23/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (72).JPEG: 384x640 3 Llicense_Plates, 32.1ms\n","image 24/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (76).JPEG: 384x640 5 Llicense_Plates, 32.1ms\n","image 25/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (80).JPEG: 384x640 4 Llicense_Plates, 32.1ms\n","image 26/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (84).JPEG: 384x640 4 Llicense_Plates, 32.1ms\n","image 27/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (88).JPEG: 384x640 5 Llicense_Plates, 32.1ms\n","image 28/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (92).JPEG: 384x640 2 Llicense_Plates, 32.1ms\n","image 29/29 /content/gdrive/MyDrive/LP_data/val/images/LP_F (96).JPEG: 384x640 2 Llicense_Plates, 32.2ms\n","Speed: 0.5ms pre-process, 32.6ms inference, 1.3ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1m/content/data/output/run_image\u001b[0m\n"]}]},{"cell_type":"markdown","source":["### 이중 검출 모델(car_images)에 대한 실사용"],"metadata":{"id":"Os7Oo8eFOago"}},{"cell_type":"code","source":["!cd /content/yolov5;python detect.py --source /content/gdrive/MyDrive/LP_data/double/images \\\n","                            --weights /mydrive/ultra_workdir/LP/weights/best.pt  --conf 0.3 \\\n","                            --project=/content/data/output --name=run_image4 --exist-ok --line-thickness 2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oZrYOlRdOaB2","executionInfo":{"status":"ok","timestamp":1686066189770,"user_tz":-540,"elapsed":15291,"user":{"displayName":"Jeolme","userId":"16749325847430807303"}},"outputId":"f752254f-5101-4c44-a692-0967ebf85f1e"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/mydrive/ultra_workdir/LP/weights/best.pt'], source=/content/gdrive/MyDrive/LP_data/double/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.3, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=/content/data/output, name=run_image4, exist_ok=True, line_thickness=2, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLOv5 🚀 v7.0-177-g89c3040 Python-3.10.11 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","\n","Fusing layers... \n","Model summary: 267 layers, 46108278 parameters, 0 gradients, 107.6 GFLOPs\n","image 1/4 /content/gdrive/MyDrive/LP_data/double/images/a.JPG: 512x640 (no detections), 49.3ms\n","image 2/4 /content/gdrive/MyDrive/LP_data/double/images/b.JPG: 480x640 (no detections), 48.7ms\n","image 3/4 /content/gdrive/MyDrive/LP_data/double/images/c.JPG: 512x640 (no detections), 40.2ms\n","image 4/4 /content/gdrive/MyDrive/LP_data/double/images/d.JPG: 448x640 (no detections), 67.8ms\n","Speed: 0.6ms pre-process, 51.5ms inference, 0.3ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1m/content/data/output/run_image4\u001b[0m\n"]}]},{"cell_type":"markdown","source":["### video inference 수행(real time)\n"],"metadata":{"id":"8mH2Vnbd1Dda"}},{"cell_type":"code","metadata":{"id":"CznFfIGOL1lV"},"source":["# !cd /content/yolov3;python detect.py --source /content/incredibles/test.mp4 \\\n","#                             --weights /mydrive/ultra_workdir/incredibles/weights/best.pt --conf 0.3 \\\n","#                             --project=/content/data/output --name=run_image --exist-ok --line-thickness 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YqXaJyREyPNQ"},"source":[],"execution_count":null,"outputs":[]}]}